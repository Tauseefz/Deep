{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include libraries which may use in implementation\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import glob\n",
    "import cv2 as img\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "path = 'C:\\\\Users\\\\Tauseef Chahal\\\\DeepLearning_Code\\\\Deep\\\\Assignment2\\\\Task3_Data\\\\'\n",
    "for i in range(10):\n",
    "    for filename in glob.glob(path+'\\\\train\\\\'+str(i)+'\\\\*.png'):\n",
    "        im = img.imread(filename)\n",
    "        train_x.append(im)\n",
    "        train_y.append(i)\n",
    "for i in range(10):\n",
    "    for filename in glob.glob(path+'\\\\test\\\\'+str(i)+'\\\\*.png'):\n",
    "        im = img.imread(filename)\n",
    "        test_x.append(im)\n",
    "        test_y.append(i)\n",
    "\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "enc.fit(train_y.reshape(train_y.shape[0],1))\n",
    "train_y_hat = enc.transform(train_y.reshape(train_y.shape[0],1))\n",
    "train_y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io #loading data from a mat file\n",
    "data = scipy.io.loadmat('filters.mat') \n",
    "filters = data['filters'] \n",
    "filters = np.array(filters)\n",
    "filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(img_patch, filters):\n",
    "    x_w = np.multiply(img_patch,filters)\n",
    "    return np.sum(x_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(x,filters):\n",
    "\n",
    "    filters_dim , filters_dim , n_b = filters.shape\n",
    "    m , image_dim , image_dim , channels = train_x.shape\n",
    "    new_img = image_dim - filters_dim + 1\n",
    "    \n",
    "    new_dim = np.zeros((m, n_b, new_img, new_img));\n",
    "    for i in range(m):\n",
    "         for j in range(n_b):\n",
    "            \n",
    "            temp_img = np.zeros((new_img, new_img))\n",
    "            for c in range(channels):\n",
    "                f = filters[:, :,j]\n",
    "                image   = x[i, :, :, c]\n",
    "                temp_img = temp_img + conv_single_step(i, j);\n",
    "\n",
    "            new_dim[i, j, :, :] = temp_img\n",
    "    return new_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(feature_map):\n",
    "    #Preparing the output of the ReLU activation function.\n",
    "    relu_out = np.zeros(feature_map.shape)\n",
    "    for map_num in range(feature_map.shape[-1]):\n",
    "        for r in np.arange(0,feature_map.shape[0]):\n",
    "            for c in np.arange(0, feature_map.shape[1]):\n",
    "                relu_out[r, c, map_num] = np.max([feature_map[r, c, map_num].all(), 0])\n",
    "    return relu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(feature_map, size=2, stride=2):\n",
    "       m , filter_dim,img_dim , img_dim =feature_map.shape\n",
    "    max_pool = np.zeros((np.uint16((m-size+1)/stride+1),\n",
    "                            np.uint16((filter_dim -size+1)/stride+1),\n",
    "                            img_dim))\n",
    "    for i in range(img_dim):\n",
    "        img = 0\n",
    "        for j in np.arange(0,m-size+1, stride):\n",
    "            fil = 0\n",
    "            for c in np.arange(0, filter_dim-size+1, stride):\n",
    "                max_pool[img, fil, i] = np.max([feature_map[j:j+size,  i:i+size]])\n",
    "                fil = fil + 1\n",
    "            img = img +1\n",
    "    return max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool = pooling((a))\n",
    "print(maxpool.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
