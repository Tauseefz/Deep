{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include libraries which may use in implementation\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#from PIL import Image as img\n",
    "\n",
    "#from keras.models import load_model\n",
    "#from keras.models import model_from_json\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=[]\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "path = 'C:\\\\Users\\\\Tauseef Chahal\\\\DeepLearning_Code\\\\Deep\\\\Assignment2\\\\Task3_Data\\\\'\n",
    "for i in range(10):\n",
    "    for filename in glob.glob(path + 'train/' +str(i)+'/*.png'):\n",
    "        im = imread(filename)\n",
    "        train_x.append(im)\n",
    "        train_y.append(i)\n",
    "for i in range(10):\n",
    "    for filename in glob.glob(path + 'test/'+str(i)+'/*.png'):\n",
    "        im = imread(filename)\n",
    "        test_x.append(im)\n",
    "        test_y.append(i)\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "enc.fit(train_y.reshape(train_y.shape[0],1))\n",
    "train_y_hat = enc.transform(train_y.reshape(train_y.shape[0],1))\n",
    "train_y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 17, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io #loading data from a mat file\n",
    "data = scipy.io.loadmat('filters.mat') \n",
    "filters = data['filters'] \n",
    "filters = np.array(filters)\n",
    "filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(X, pad):\n",
    "\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad)), 'constant', constant_values=0)\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(img_patch, filters):\n",
    "    x_w = np.multiply(img_patch,filters)\n",
    "    return np.sum(x_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(img, filters, stride=1, pad=0):\n",
    "    \n",
    "    (n_H_prev, n_W_prev, n_C_prev) = img.shape\n",
    "    ( f, n_C_prev, n_C) = filters.shape\n",
    "    \n",
    "    n_H = int((n_H_prev - f + 2 *pad)/stride)+1\n",
    "    n_W = int((n_W_prev -f + 2* pad)/stride)+1\n",
    "    \n",
    "    A_prev_pad = zero_pad(img, pad)\n",
    "    \n",
    "    Z = np.zeros(( n_H, n_W, n_C))\n",
    "    for i in range(n_H_prev):\n",
    "        a_prev_pad = A_prev_pad[i]\n",
    "        for h in range(n_H):                          \n",
    "             for w in range(n_W):                       \n",
    "                for c in range(n_C):                   \n",
    "                     # Find the corners of the current \"slice\" (≈4 lines)\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end ]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, W[...,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-e25a3e6acdf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                \"stride\": 1}\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Z's mean =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cache_conv[0][1][2][3] =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_conv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-a4ffe26c993a>\u001b[0m in \u001b[0;36mconv_forward\u001b[1;34m(img, filters, stride, pad)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mn_H_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_W_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_C_prev\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;33m(\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_C_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_C\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "def convolution(image, filt, bias, s=1):\n",
    "    (n_f, n_c_f, f, _) = filt.shape # filter dimensions\n",
    "    n_c, in_dim, _ = image.shape # image dimensions\n",
    "    \n",
    "    out_dim = int((in_dim - f)/s)+1 # calculate output dimensions\n",
    "    \n",
    "    # ensure that the filter dimensions match the dimensions of the input image\n",
    "    assert n_c == n_c_f, \"Dimensions of filter must match dimensions of input image\"\n",
    "    \n",
    "    out = np.zeros((n_f,out_dim,out_dim)) # create the matrix to hold the values of the convolution operation\n",
    "    \n",
    "    # convolve each filter over the image\n",
    "    for curr_f in range(n_f):\n",
    "        curr_y = out_y = 0\n",
    "        # move filter vertically across the image\n",
    "        while curr_y + f <= in_dim:\n",
    "            curr_x = out_x = 0\n",
    "            # move filter horizontally across the image \n",
    "            while curr_x + f <= in_dim:\n",
    "                # perform the convolution operation and add the bias\n",
    "                out[curr_f, out_y, out_x] = np.sum(filt[curr_f] * image[:,curr_y:curr_y+f, curr_x:curr_x+f]) + bias[curr_f]\n",
    "                curr_x += s\n",
    "                out_x += 1\n",
    "            curr_y += s\n",
    "            out_y += 1\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
